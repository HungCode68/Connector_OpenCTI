from multiprocessing import context
import os
import time
import json
from pycti import OpenCTIApiClient
from pycti import OpenCTIApiClient
import stix2
import geoip2.database
from datetime import datetime
from concurrent.futures import ProcessPoolExecutor

from utils.fetcher import parse_generic_file
from utils.api_client import ThreatAPIClient
from utils.config_helper import ConfigLoader
from utils.converter import StixConverter

from dotenv import load_dotenv
load_dotenv()

# --- WORKER GLOBAL VARIABLES ---
# C√°c bi·∫øn n√†y s·∫Ω ƒë∆∞·ª£c kh·ªüi t·∫°o ri√™ng cho t·ª´ng ti·∫øn tr√¨nh con ƒë·ªÉ tr√°nh xung ƒë·ªôt
worker_api_client = None
worker_asn_reader = None
worker_city_reader = None
worker_converter = None

def init_worker(keys, paths, author_id):
    """
    H√†m kh·ªüi t·∫°o t√†i nguy√™n cho m·ªói Worker.
    keys: Dict ch·ª©a API keys
    paths: Dict ch·ª©a ƒë∆∞·ªùng d·∫´n GeoIP
    """
    global worker_api_client, worker_asn_reader, worker_city_reader, worker_converter
    
    # Kh·ªüi t·∫°o API Client v·ªõi ƒë·∫ßy ƒë·ªß key
    worker_api_client = ThreatAPIClient(
        abuse_key=keys.get('abuseipdb'),
        grey_key=keys.get('greynoise'),
        threatfox_key=keys.get('threatfox'),
        vt_key=keys.get('virustotal')
    )
    
    # Kh·ªüi t·∫°o Converter
    worker_converter = StixConverter(author_id)
    
    # M·ªü k·∫øt n·ªëi GeoIP
    if paths.get('asn') and os.path.exists(paths['asn']):
        worker_asn_reader = geoip2.database.Reader(paths['asn'])
    if paths.get('city') and os.path.exists(paths['city']):
        worker_city_reader = geoip2.database.Reader(paths['city'])

def process_indicator(task_data):
    """
    H√†m x·ª≠ l√Ω logic cho 1 Indicator (IP, Hash, ho·∫∑c Domain).
    task_data bao g·ªìm: (value, data_type, tags, source_desc)
    """
    item_obj = task_data['item']
    dtype = task_data['dtype']
    value = item_obj.get('value')
    csv_meta = item_obj.get('meta', {})
    global worker_api_client, worker_asn_reader, worker_city_reader, worker_converter
    
    # Chu·∫©n b·ªã context d·ªØ li·ªáu ƒë·ªÉ l√†m gi√†u
    context = {
        "score": 0,
        "tags": task_data['tags'].copy(),
        "source_desc": task_data['desc'],
        "categories": [],    # D√†nh cho AbuseIPDB categories
        "vt_data": None,     # D√†nh cho VirusTotal
        "domain_info": None, # D√†nh cho Domain Whois
        "threatfox": None,   # D√†nh cho ThreatFox
        "geo_info": {"isp": "Unknown", "loc": "Unknown"}
    }

    try:
        if csv_meta:
            # X·ª≠ l√Ω Severity -> Score
            severity = csv_meta.get('metadata_severity', 'medium').lower()
            if severity == 'high': context['score'] = 90
            elif severity == 'medium': context['score'] = 60
            elif severity == 'low': context['score'] = 30

            severity_score = csv_meta.get('metadata_severity_score')
            if severity_score:
                try:
                    # Chuy·ªÉn ƒëi·ªÉm t·ª´ thang 10 sang thang 100
                    context['score'] = int(float(severity_score) * 10)
                except ValueError:
                    pass
            
            # B·ªï sung Tags t·ª´ Category
            if csv_meta.get('metadata_category'):
                context['tags'].append(csv_meta['metadata_category'].replace(" ", "-").lower())
                
            # L√†m gi√†u Description
            extra_info = []
            if csv_meta.get('metadata_tool'): extra_info.append(f"Tool: {csv_meta['metadata_tool']}")
            if csv_meta.get('metadata_description'): extra_info.append(f"Desc: {csv_meta['metadata_description']}")
            if csv_meta.get('metadata_link'): extra_info.append(f"Ref: {csv_meta['metadata_link']}")
            
            if extra_info:
                context['source_desc'] += " | " + " | ".join(extra_info)

        # --- X·ª¨ L√ù IP ---
        if dtype == 'ip':
            # G·ªçi AbuseIPDB
            abuse_res = worker_api_client.check_abuseipdb(value)
            if abuse_res:
                context['score'] = max(context['score'], abuse_res.get('score', 0))
                context['categories'] = abuse_res.get('categories', [])
                
                # Logic GeoIP Local (∆Øu ti√™n local h∆°n API ƒë·ªÉ ti·∫øt ki·ªám quota)
                if worker_asn_reader:
                    try: context["geo_info"]["isp"] = worker_asn_reader.asn(value).autonomous_system_organization
                    except: pass
                if worker_city_reader:
                    try: 
                        r = worker_city_reader.city(value)
                        context["geo_info"]["loc"] = f"{r.city.name}, {r.country.name}"
                    except: pass
            
            # G·ªçi GreyNoise (Optional)
            # gn_res = worker_api_client.check_greynoise(value)

        # --- X·ª¨ L√ù HASH (SHA256/MD5) ---
        elif dtype in ['sha256', 'md5']:
            vt_res = worker_api_client.check_virustotal_hash(value)
            if vt_res:
                context['vt_data'] = vt_res
                # N·∫øu > 2 engine ph√°t hi·ªán th√¨ tƒÉng ƒëi·ªÉm cao
                if vt_res.get('malicious_count', 0) > 2:
                    context['score'] = max(context['score'], 85)

        # --- X·ª¨ L√ù DOMAIN ---
        elif dtype == 'domain':
            dom_res = worker_api_client.check_domain_info(value)
            context['domain_info'] = dom_res
            # N·∫øu domain m·ªõi t·∫°o < 30 ng√†y -> ƒê√°ng ng·ªù
            age = dom_res.get('age_days')
            if age is not None and age < 30:
                context['score'] = 70
                context['tags'].append("newly-registered-domain")
            elif age is None:
            # (T√πy ch·ªçn) N·∫øu kh√¥ng l·∫•y ƒë∆∞·ª£c tu·ªïi, c√≥ th·ªÉ coi l√† ƒë√°ng ng·ªù nh·∫π ho·∫∑c b·ªè qua
                context['source_desc'] += " | Whois Lookup Failed"

        # URL X·ª¨ L√ù URL ---
        elif dtype == 'url':
            vt = worker_api_client.check_virustotal_url(value)
            if vt:
                context['vt_data'] = vt
                if vt.get('malicious_count', 0) > 2: context['score'] = 80
        
        # USER-AGENT / FILENAME / NAMED-PIPE 
        elif dtype in ['user-agent', 'filename', 'named-pipe']:
            # Ch·ªâ g√°n ƒëi·ªÉm m·∫∑c ƒë·ªãnh n·∫øu ch∆∞a c√≥ ƒëi·ªÉm (t·ª´ metadata)
            if context['score'] == 0:
                context['score'] = 60

        # --- THREATFOX (Ki·ªÉm tra ch√©o cho t·∫•t c·∫£ c√°c lo·∫°i) ---
        tf_res = worker_api_client.check_threatfox(value)
        if tf_res:
            context['threatfox'] = tf_res
            context['score'] = max(context['score'], 95) # ThreatFox ƒë·ªô tin c·∫≠y r·∫•t cao

        # --- CHUY·ªÇN ƒê·ªîI SANG STIX ---
        # H√†m create_stix_bundle m·ªõi ƒë√£ h·ªó tr·ª£ nh·∫≠n context t·ªïng qu√°t
        return worker_converter.create_stix_bundle(value, dtype, context)

    except Exception as e:
        print(f" [Error] {dtype} {value}: {e}") # Uncomment ƒë·ªÉ debug
        return []

# --- CLASS CH√çNH ---
class ProductionConnector:

    def download_latest_feeds(self):
        """T·∫£i d·ªØ li·ªáu m·ªõi nh·∫•t t·ª´ URL trong config.yml tr∆∞·ªõc khi x·ª≠ l√Ω"""
        import requests
        print(">>> üîÑ ƒêANG T·∫¢I D·ªÆ LI·ªÜU M·ªöI NH·∫§T...")
        # ƒê·∫£m b·∫£o th∆∞ m·ª•c data t·ªìn t·∫°i
        os.makedirs(self.cfg.get_path('../data'), exist_ok=True)
        
        for feed in self.feeds:
            url = feed.get('url')
            file_path = self.cfg.get_path(feed['path'])
            if url:
                try:
                    print(f" -> ƒêang t·∫£i: {url}")
                    response = requests.get(url, timeout=30)
                    response.raise_for_status()
                    with open(file_path, 'wb') as f:
                        f.write(response.content)
                except Exception as e:
                    print(f"    [!] L·ªói t·∫£i {url}: {e}")


    def __init__(self):
        # Load Config
        self.cfg = ConfigLoader(os.path.dirname(os.path.abspath(__file__)))
        
        # Load Keys & Paths
        self.keys = {
            'abuseipdb': self.cfg.get('keys', 'abuseipdb'),
            'greynoise': self.cfg.get('keys', 'greynoise'),
            'threatfox': self.cfg.get('keys', 'threatfox'),
            'virustotal': self.cfg.get('keys', 'virustotal')
        }
        
        self.paths = {
            'asn': self.cfg.get_path(self.cfg.get('keys', 'geoip_asn_path')),
            'city': self.cfg.get_path(self.cfg.get('keys', 'geoip_city_path'))
        }

        # Load danh s√°ch ngu·ªìn d·ªØ li·ªáu (Feeds)
        self.feeds = self.cfg.get('feeds', default=[])
        
        # Load Output Path
        self.output_path = self.cfg.get_path(self.cfg.get('output', 'path'))
        
        # C·∫•u h√¨nh th·ªùi gian ch·∫°y ƒë·ªãnh k·ª≥
        interval_str = self.cfg.get('connector', 'exposure_time') or '1h'
        try:
            self.interval = int(interval_str.replace('h', '')) * 3600
        except:
            self.interval = 3600 # M·∫∑c ƒë·ªãnh 1 gi·ªù

    def run(self):
        self.download_latest_feeds()
        print(f"[*] Connector kh·ªüi ƒë·ªông v·ªõi {len(self.feeds)} ngu·ªìn d·ªØ li·ªáu.")
        print(f"\n[{datetime.now()}] >>> B·∫Øt ƒë·∫ßu chu k·ª≥ qu√©t...")
        self.process_data()
        print(f"[{datetime.now()}] >>> Ho√†n th√†nh chu k·ª≥ ch·∫°y!")

    def process_data(self):
        start_time = time.time()
        
        # T·∫°o Identity
        author = stix2.Identity(
            name=self.cfg.get('connector', 'name'),
            identity_class="organization",
            description="Automated Threat Intelligence Connector"
        )
        
        all_objects = [author]
        all_tasks = []

        # GOM D·ªÆ LI·ªÜU T·ª™ T·∫§T C·∫¢ C√ÅC NGU·ªíN
        for feed in self.feeds:
            f_path = self.cfg.get_path(feed['path'])
            f_type = feed['type']
            
            # B·ªè qua n·∫øu c·∫•u h√¨nh sai path
            if not f_path: continue
                
            print(f" -> ƒêang ƒë·ªçc ngu·ªìn: {os.path.basename(f_path)} ({f_type})...")
            
            # S·ª≠ d·ª•ng parse_generic_file thay v√¨ parse_local_file c≈©
            _, items = parse_generic_file(f_path, f_type)
            
            # (T√πy ch·ªçn) Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng items m·ªói feed ƒë·ªÉ test
            items = items[:50] 
            
            for item in items:
                # ƒê√≥ng g√≥i task ƒë·ªÉ g·ª≠i cho Worker
                all_tasks.append({
                    "item": item,
                    "dtype": f_type,
                    "tags": feed['tags'],
                    "desc": feed['description']
                })

        print(f" -> T·ªïng c·ªông: {len(all_tasks)} indicators c·∫ßn x·ª≠ l√Ω.")
        if len(all_tasks) == 0:
            print(" [!] C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu n√†o! Ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n file CSV trong config.yml")

        # X·ª¨ L√ù ƒêA LU·ªíNG
        max_workers = os.cpu_count() or 4
        with ProcessPoolExecutor(
            max_workers=max_workers,
            initializer=init_worker,
            initargs=(self.keys, self.paths, author.id)
        ) as executor:
            # map s·∫Ω tr·∫£ v·ªÅ list c√°c list STIX objects
            results = list(executor.map(process_indicator, all_tasks))
            
            for res in results:
                all_objects.extend(res)

        # XU·∫§T FILE JSON
        print(f" -> ƒêang ƒë√≥ng g√≥i {len(all_objects)} STIX objects...")
        bundle = stix2.Bundle(objects=all_objects, allow_custom=True)
        bundle_json = bundle.serialize()
        
        #  V·∫´n l∆∞u file local ƒë·ªÉ backup
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        backup_filename = f"backup_bundle_{timestamp}.json"
        
        try:
            with open(backup_filename, "w", encoding="utf-8") as f:
                f.write(bundle_json)
            print(f" üíæ ƒê√£ l∆∞u file backup local t·∫°i: {backup_filename}")
        except Exception as e:
            print(f" [!] L·ªói l∆∞u file backup: {e}")

        # ƒê·∫®Y D·ªÆ LI·ªÜU L√äN OPENCTI
        opencti_url = os.getenv('OPENCTI_URL') or self.cfg.get('opencti', 'url')
        opencti_token = os.getenv('OPENCTI_TOKEN') or self.cfg.get('opencti', 'token')

        if opencti_url and opencti_token:
            print(f" -> üöÄ ƒêang k·∫øt n·ªëi t·ªõi OpenCTI: {opencti_url}")
            try:
                # Kh·ªüi t·∫°o Client
                client = OpenCTIApiClient(opencti_url, opencti_token)
                
                # Chuy·ªÉn ƒë·ªïi t·ª´ String sang Dictionary tr∆∞·ªõc khi upload
                bundle_dict = json.loads(bundle_json) 
                
                print(" -> üì° ƒêang ƒë·∫©y d·ªØ li·ªáu l√™n h·ªá th·ªëng... Vui l√≤ng ch·ªù...")
                
                # G·ª≠i Dictionary v√†o thay v√¨ g·ª≠i String
                client.stix2.import_bundle(bundle_dict) 

                print(" ‚úÖ TH√ÄNH C√îNG! D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t l√™n OpenCTI.")
            except Exception as e:
                print(f" ‚ùå L·ªñI UPLOAD OPENCTI: {e}")
                # In chi ti·∫øt l·ªói ƒë·ªÉ debug n·∫øu c·∫ßn
                import traceback
                traceback.print_exc()
        else:
            print(" [!] B·ªè qua b∆∞·ªõc upload v√¨ ch∆∞a c·∫•u h√¨nh 'opencti' trong config.yml")
            
        end_time = time.time()
        print(f"=== Ho√†n th√†nh trong {round(end_time - start_time, 2)} gi√¢y ===")

if __name__ == "__main__":
    try:
        connector = ProductionConnector()
        connector.run()
    except Exception as e:
        print(f"CRITICAL ERROR: {e}")